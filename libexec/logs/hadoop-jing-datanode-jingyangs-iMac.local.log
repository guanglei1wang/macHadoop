2020-06-14 18:32:15,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 18:32:15,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 18:32:16,102 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 18:32:16,313 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/dfs/data
2020-06-14 18:32:16,395 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 18:32:16,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 18:32:16,487 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 18:32:16,650 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:32:16,656 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 18:32:16,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 18:32:16,661 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:32:16,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 18:32:16,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 18:32:16,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 18:32:16,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 18:32:16,718 INFO org.eclipse.jetty.util.log: Logging initialized @1364ms
2020-06-14 18:32:16,791 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 18:32:16,794 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 18:32:16,799 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 18:32:16,801 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 18:32:16,801 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 18:32:16,801 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 18:32:16,824 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 53436
2020-06-14 18:32:16,824 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 18:32:16,845 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@17f9344b{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 18:32:16,846 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54e81b21{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 18:32:16,908 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3d7cc3cb{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 18:32:16,920 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@36322047{HTTP/1.1,[http/1.1]}{localhost:53436}
2020-06-14 18:32:16,921 INFO org.eclipse.jetty.server.Server: Started @1566ms
2020-06-14 18:32:17,087 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 18:32:17,093 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 18:32:17,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 18:32:17,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 18:32:17,155 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 18:32:17,171 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 18:32:17,388 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 18:32:17,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 18:32:17,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 18:32:17,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 18:32:17,437 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 18:32:17,437 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 18:32:18,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:19,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:20,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:21,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:22,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:23,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:24,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:25,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:26,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:27,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:27,565 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:32:33,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:34,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:35,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:36,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:37,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:38,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:39,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:40,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:41,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:42,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:42,609 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:32:48,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:49,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:50,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:51,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:52,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:53,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:54,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:55,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:56,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:57,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:32:57,650 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:33:03,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:04,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:05,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:06,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:07,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:08,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:09,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:10,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:11,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:12,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:12,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:33:18,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:19,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:20,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:21,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:22,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:23,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:24,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:25,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:26,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:27,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:27,727 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:33:33,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:34,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:35,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:36,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:37,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:38,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:39,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:40,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:41,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:42,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:42,766 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:33:48,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:49,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:50,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:33:50,926 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 18:33:50,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 18:34:06,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 18:34:06,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 18:34:06,957 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 18:34:07,150 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/dfs/data
2020-06-14 18:34:07,235 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 18:34:07,333 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 18:34:07,333 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 18:34:07,493 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:34:07,499 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 18:34:07,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 18:34:07,504 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:34:07,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 18:34:07,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 18:34:07,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 18:34:07,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 18:34:07,566 INFO org.eclipse.jetty.util.log: Logging initialized @1339ms
2020-06-14 18:34:07,639 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 18:34:07,642 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 18:34:07,648 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 18:34:07,650 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 18:34:07,650 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 18:34:07,650 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 18:34:07,671 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 53551
2020-06-14 18:34:07,672 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 18:34:07,692 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6979efad{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 18:34:07,693 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4a67318f{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 18:34:07,758 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@72ab05ed{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 18:34:07,763 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@4a31c2ee{HTTP/1.1,[http/1.1]}{localhost:53551}
2020-06-14 18:34:07,763 INFO org.eclipse.jetty.server.Server: Started @1536ms
2020-06-14 18:34:07,912 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 18:34:07,918 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 18:34:07,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 18:34:07,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 18:34:07,962 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 18:34:07,972 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 18:34:08,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 18:34:08,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 18:34:08,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 18:34:08,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 18:34:08,171 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 18:34:08,171 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 18:34:09,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:10,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:11,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:12,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:13,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:14,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:15,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:16,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:17,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:18,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:18,282 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:34:24,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:25,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:26,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:27,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:28,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:29,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:30,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:31,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:32,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:33,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:33,323 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:34:39,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:40,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:41,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:42,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:43,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:44,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:45,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:46,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:47,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:48,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:48,356 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:34:54,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:55,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:56,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:57,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:58,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:34:59,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:00,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:01,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:02,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:03,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:03,401 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:35:09,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:10,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:11,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:12,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:13,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:14,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:15,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:16,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:17,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:18,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:18,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:35:24,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:25,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:26,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:27,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:28,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:29,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:30,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:31,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:32,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:33,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:33,493 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:35:39,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:40,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:41,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:42,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:43,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:44,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:45,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:46,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:47,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:48,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:48,538 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:35:54,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:55,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:56,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:57,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:58,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:35:59,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:00,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:01,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:02,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:03,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:03,583 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:36:09,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:10,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:11,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:12,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:13,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:14,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:15,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:16,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:17,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:18,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:18,792 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:36:24,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:25,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:26,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:27,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:28,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:29,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:30,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:31,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:32,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:33,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:33,837 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:36:39,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:40,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:41,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:42,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:43,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:44,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:45,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:46,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:47,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:48,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:48,874 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:36:54,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:55,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:56,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:57,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:58,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:36:59,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:00,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:01,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:02,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:03,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:03,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:37:09,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:10,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:11,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:12,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:13,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:14,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:15,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:16,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:17,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:18,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:18,959 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:37:24,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:25,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:26,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:27,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:28,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:29,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:30,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:31,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:32,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:33,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:34,000 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:37:40,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:41,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:42,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:43,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:44,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:45,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:46,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:47,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:48,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:49,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:49,041 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:37:55,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:56,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:57,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:58,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:37:59,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:00,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:01,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:02,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:03,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:04,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:04,084 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:38:10,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:11,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:12,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:13,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:14,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:15,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:16,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:17,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:18,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:19,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:19,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:38:25,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:26,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:27,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:28,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:29,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:30,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:31,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:32,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:33,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:34,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:34,370 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:38:40,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:41,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:42,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:43,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:44,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:45,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:46,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:47,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:48,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:49,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:49,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:38:55,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:56,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:57,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:58,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:38:59,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:00,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:01,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:02,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:03,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:04,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:04,448 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:39:10,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:11,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:12,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:13,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:14,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:15,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:16,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:17,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:18,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:19,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:19,497 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:39:25,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:26,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:27,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:28,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:29,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:30,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:31,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:32,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:33,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:34,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:34,537 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:39:40,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:41,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:42,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:43,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:44,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:45,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:46,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:47,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:48,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:49,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:49,580 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:39:55,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:56,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:57,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:58,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:39:59,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:00,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:01,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:02,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:03,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:04,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:04,619 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:40:10,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:11,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:12,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:13,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:14,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:15,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:16,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:17,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:18,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:19,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:19,853 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:40:25,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:26,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:27,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:28,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:29,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:30,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:31,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:32,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:33,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:34,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:34,897 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:40:40,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:41,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:42,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:43,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:44,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:45,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:46,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:47,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:48,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:49,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:49,932 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:40:55,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:56,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:57,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:58,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:40:59,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:00,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:01,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:02,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:03,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:04,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:04,970 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:41:10,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:11,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:12,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:13,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:14,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:15,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:17,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:18,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:19,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:20,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:20,017 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:41:26,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:27,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:28,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:29,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:30,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:31,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:32,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:33,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:34,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:35,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:35,058 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:41:41,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:42,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:43,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:44,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:45,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:46,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:47,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:48,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:49,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:50,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:50,099 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:41:56,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:57,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:58,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:41:59,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:00,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:01,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:02,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:03,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:04,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:05,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:05,136 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:42:11,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:12,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:13,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:14,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:15,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:16,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:17,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:18,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:19,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:20,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:20,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:42:26,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:27,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:28,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:29,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:30,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:31,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:32,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:33,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:34,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:35,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:35,435 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:42:41,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:42,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:43,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:44,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:45,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:46,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:47,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:48,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:49,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:50,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:50,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:42:56,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:57,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:58,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:42:59,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:00,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:01,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:02,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:03,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:04,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:05,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:05,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:43:11,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:12,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:13,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:14,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:15,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:16,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:17,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:18,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:19,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:20,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:20,569 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:43:26,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:27,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:28,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:29,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:30,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:31,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:32,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:33,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:34,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:35,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:35,617 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:43:41,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:42,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:43,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:44,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:45,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:46,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:47,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:48,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:49,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:50,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:50,657 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:43:56,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:57,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:58,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:43:59,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:00,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:01,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:02,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:03,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:04,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:05,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:05,686 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:44:08,185 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:213)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:224)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:3146)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at java.base/sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:260)
	at java.management/com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at java.management/com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at java.management/com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at java.management/com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at java.management/com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at java.management/com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:701)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:93)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:300)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
	at java.base/java.lang.Thread.run(Thread.java:844)
2020-06-14 18:44:08,192 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:213)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:224)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:3119)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at java.base/sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:260)
	at java.management/com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at java.management/com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at java.management/com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at java.management/com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at java.management/com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at java.management/com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at java.management/com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:701)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:93)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:514)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:300)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
	at java.base/java.lang.Thread.run(Thread.java:844)
2020-06-14 18:44:11,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:12,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:13,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:14,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:15,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:16,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:17,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:18,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:19,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:20,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:20,878 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:44:26,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:27,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:28,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:29,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:30,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:31,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:32,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:33,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:34,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:35,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:35,907 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-06-14 18:44:41,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:42,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:43,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:44,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:45,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:46,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:47,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-06-14 18:44:48,119 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 18:44:48,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 18:45:02,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 18:45:02,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 18:45:02,817 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 18:45:03,029 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 18:45:03,116 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 18:45:03,222 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 18:45:03,222 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 18:45:03,395 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:45:03,401 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 18:45:03,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 18:45:03,405 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 18:45:03,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 18:45:03,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 18:45:03,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 18:45:03,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 18:45:03,465 INFO org.eclipse.jetty.util.log: Logging initialized @1547ms
2020-06-14 18:45:03,544 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 18:45:03,547 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 18:45:03,552 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 18:45:03,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 18:45:03,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 18:45:03,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 18:45:03,576 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54232
2020-06-14 18:45:03,577 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 18:45:03,599 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@315ba14a{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 18:45:03,600 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 18:45:03,671 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@17d238b1{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 18:45:03,677 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@788496d8{HTTP/1.1,[http/1.1]}{localhost:54232}
2020-06-14 18:45:03,677 INFO org.eclipse.jetty.server.Server: Started @1760ms
2020-06-14 18:45:03,840 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 18:45:03,846 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 18:45:03,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 18:45:03,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 18:45:03,887 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 18:45:03,897 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 18:45:04,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 18:45:04,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 18:45:04,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 18:45:04,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 18:45:04,123 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 18:45:04,123 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 18:45:04,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-14 18:45:04,385 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-14 18:45:04,394 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 49778@localhost
2020-06-14 18:45:04,395 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data is not formatted for namespace 1881303659. Formatting...
2020-06-14 18:45:04,395 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-a0afa056-2184-42bb-9b38-9b26368747d7 for directory /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data 
2020-06-14 18:45:04,426 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-14 18:45:04,427 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-14 18:45:04,428 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data and block pool id BP-810358025-127.0.0.1-1592131473415 is not formatted. Formatting ...
2020-06-14 18:45:04,428 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-810358025-127.0.0.1-1592131473415 directory /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current
2020-06-14 18:45:04,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=null
2020-06-14 18:45:04,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-14 18:45:04,549 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-14 18:45:04,549 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-14 18:45:04,553 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-14 18:45:04,559 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 18:45:04,567 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 18:45:04,568 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 18:45:04,569 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 18:45:04,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 27ms
2020-06-14 18:45:04,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 28ms
2020-06-14 18:45:04,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 18:45:04,598 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-14 18:45:04,599 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 1ms
2020-06-14 18:45:04,600 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 3ms
2020-06-14 18:45:04,601 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 18:45:04,602 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): finished scanning block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 18:45:04,614 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-06-14 18:45:04,641 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/14/20, 8:21 PM with interval of 21600000ms
2020-06-14 18:45:04,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-14 18:45:04,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-14 18:45:04,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-14 18:45:04,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x32ac7214c1887683,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 18:45:04,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:00:14,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x32ac7214c1887684,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 19:00:14,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:06:35,884 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 19:06:35,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 19:06:55,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 19:06:55,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 19:06:55,798 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 19:06:56,012 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:06:56,103 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 19:06:56,208 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 19:06:56,208 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 19:06:56,368 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 19:06:56,371 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 19:06:56,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 19:06:56,379 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 19:06:56,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 19:06:56,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 19:06:56,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 19:06:56,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 19:06:56,437 INFO org.eclipse.jetty.util.log: Logging initialized @1466ms
2020-06-14 19:06:56,513 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 19:06:56,516 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 19:06:56,521 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 19:06:56,523 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 19:06:56,523 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 19:06:56,523 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 19:06:56,542 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 54647
2020-06-14 19:06:56,543 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 19:06:56,564 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@315ba14a{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 19:06:56,565 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 19:06:56,634 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@17d238b1{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 19:06:56,639 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@31ff1390{HTTP/1.1,[http/1.1]}{localhost:54647}
2020-06-14 19:06:56,639 INFO org.eclipse.jetty.server.Server: Started @1668ms
2020-06-14 19:06:56,788 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 19:06:56,793 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 19:06:56,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 19:06:56,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 19:06:56,824 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 19:06:56,833 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 19:06:56,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 19:06:57,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 19:06:57,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 19:06:57,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 19:06:57,034 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 19:06:57,034 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 19:06:57,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-14 19:06:57,272 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-14 19:06:57,287 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 53424@localhost
2020-06-14 19:06:57,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:06:57,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:06:57,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-14 19:06:57,453 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-14 19:06:57,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-14 19:06:57,465 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-14 19:06:57,474 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:06:57,508 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:06:57,510 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:06:57,514 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 19:06:57,525 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 8192
2020-06-14 19:06:57,540 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 27ms
2020-06-14 19:06:57,541 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 31ms
2020-06-14 19:06:57,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 19:06:57,542 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-14 19:06:57,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 2ms
2020-06-14 19:06:57,544 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 2ms
2020-06-14 19:06:57,567 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1813087034 ms.
2020-06-14 19:06:57,586 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/14/20, 8:30 PM with interval of 21600000ms
2020-06-14 19:06:57,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-14 19:06:57,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-14 19:06:57,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-14 19:06:57,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4cd48b2f0e3a60a5,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 19:06:57,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:15:34,341 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "localhost/127.0.0.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy18.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-06-14 19:15:34,877 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 19:15:34,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 19:15:56,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 19:15:56,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 19:15:56,595 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 19:15:56,894 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:15:57,055 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 19:15:57,200 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 19:15:57,200 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 19:15:57,399 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 19:15:57,401 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 19:15:57,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 19:15:57,409 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 19:15:57,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 19:15:57,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 19:15:57,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 19:15:57,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 19:15:57,489 INFO org.eclipse.jetty.util.log: Logging initialized @2030ms
2020-06-14 19:15:57,596 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 19:15:57,599 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 19:15:57,609 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 19:15:57,612 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 19:15:57,612 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 19:15:57,612 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 19:15:57,633 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 55072
2020-06-14 19:15:57,634 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 19:15:57,662 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@54f5f647{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 19:15:57,662 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5a6d5a8f{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 19:15:57,794 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@19f040ba{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 19:15:57,803 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@56e00e81{HTTP/1.1,[http/1.1]}{localhost:55072}
2020-06-14 19:15:57,803 INFO org.eclipse.jetty.server.Server: Started @2344ms
2020-06-14 19:15:57,996 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 19:15:58,004 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 19:15:58,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 19:15:58,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 19:15:58,054 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 19:15:58,066 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 19:15:58,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 19:15:58,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 19:15:58,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 19:15:58,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 19:15:58,483 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 19:15:58,484 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 19:15:58,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-14 19:15:58,718 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-14 19:15:58,727 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 55241@localhost
2020-06-14 19:15:58,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:15:58,761 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:15:58,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-14 19:15:58,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-14 19:15:58,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-14 19:15:58,897 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-14 19:15:58,903 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:15:58,910 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 19:15:58,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 19:15:58,912 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 19:15:58,921 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 8192
2020-06-14 19:15:58,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 24ms
2020-06-14 19:15:58,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 24ms
2020-06-14 19:15:58,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 19:15:58,937 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-14 19:15:58,939 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 2ms
2020-06-14 19:15:58,939 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 2ms
2020-06-14 19:15:58,956 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1812545645 ms.
2020-06-14 19:15:58,981 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/14/20, 9:29 PM with interval of 21600000ms
2020-06-14 19:15:58,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-14 19:15:59,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-14 19:15:59,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-14 19:15:59,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5691a8ee4fd2b74f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 54 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 19:15:59,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 20:01:28,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5691a8ee4fd2b750,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 20:01:28,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:29:57,979 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-810358025-127.0.0.1-1592131473415 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-06-14 21:41:33,377 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 21:41:33,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 21:41:53,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = localhost/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 21:41:53,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 21:41:53,545 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 21:41:53,734 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:41:53,814 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 21:41:53,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 21:41:53,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 21:41:54,107 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 21:41:54,109 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 21:41:54,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 21:41:54,118 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 21:41:54,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 21:41:54,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-06-14 21:41:54,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 21:41:54,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 21:41:54,172 INFO org.eclipse.jetty.util.log: Logging initialized @1357ms
2020-06-14 21:41:54,243 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 21:41:54,246 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 21:41:54,251 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 21:41:54,253 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 21:41:54,253 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 21:41:54,253 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 21:41:54,269 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 56933
2020-06-14 21:41:54,270 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 21:41:54,290 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@315ba14a{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 21:41:54,291 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 21:41:54,357 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@17d238b1{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 21:41:54,362 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@1951ae30{HTTP/1.1,[http/1.1]}{localhost:56933}
2020-06-14 21:41:54,362 INFO org.eclipse.jetty.server.Server: Started @1547ms
2020-06-14 21:41:54,502 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-06-14 21:41:54,508 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 21:41:54,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 21:41:54,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 21:41:54,547 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 21:41:54,556 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 21:41:54,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-06-14 21:41:54,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 21:41:54,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 21:41:54,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 21:41:54,725 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 21:41:54,725 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 21:41:54,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-14 21:41:54,935 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-14 21:41:54,944 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 57638@localhost
2020-06-14 21:41:54,973 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:41:54,973 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:41:54,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-14 21:41:55,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-14 21:41:55,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-14 21:41:55,078 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-14 21:41:55,103 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:41:55,111 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:41:55,112 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:41:55,113 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 21:41:55,121 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 12288
2020-06-14 21:41:55,135 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 22ms
2020-06-14 21:41:55,135 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 22ms
2020-06-14 21:41:55,136 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 21:41:55,136 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-14 21:41:55,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 2ms
2020-06-14 21:41:55,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 2ms
2020-06-14 21:41:55,154 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1803789447 ms.
2020-06-14 21:41:55,171 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/15/20, 12:22 AM with interval of 21600000ms
2020-06-14 21:41:55,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-14 21:41:55,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-14 21:41:55,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-14 21:41:55,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x3067ba09a56e88ab,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 21:41:55,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:43:17,749 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-14 21:43:17,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at localhost/127.0.0.1
************************************************************/
2020-06-14 21:43:33,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = jingyangs-iMac.local/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-14 21:43:33,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-14 21:43:33,391 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-14 21:43:33,581 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:43:33,657 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-14 21:43:33,753 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-14 21:43:33,753 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-14 21:43:33,910 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 21:43:33,912 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-14 21:43:33,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-14 21:43:33,919 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-14 21:43:33,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-14 21:43:33,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0:0:0:0:0:0:0:0:9866
2020-06-14 21:43:33,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-14 21:43:33,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-14 21:43:33,971 INFO org.eclipse.jetty.util.log: Logging initialized @1316ms
2020-06-14 21:43:34,044 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-14 21:43:34,046 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-14 21:43:34,052 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-14 21:43:34,053 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-14 21:43:34,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-14 21:43:34,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-14 21:43:34,070 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 56983
2020-06-14 21:43:34,071 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-14 21:43:34,092 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-14 21:43:34,093 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38d5b107{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-14 21:43:34,159 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3d7cc3cb{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-14 21:43:34,164 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@759d81f3{HTTP/1.1,[http/1.1]}{localhost:56983}
2020-06-14 21:43:34,165 INFO org.eclipse.jetty.server.Server: Started @1510ms
2020-06-14 21:43:34,321 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0:0:0:0:0:0:0:0:9864
2020-06-14 21:43:34,327 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-14 21:43:34,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-14 21:43:34,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-14 21:43:34,360 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-14 21:43:34,371 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-14 21:43:34,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0:0:0:0:0:0:0:0:9867
2020-06-14 21:43:34,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-14 21:43:34,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-14 21:43:34,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-14 21:43:34,547 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-14 21:43:34,548 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-14 21:43:34,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-14 21:43:34,757 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-14 21:43:34,771 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 60297@jingyangs-iMac.local
2020-06-14 21:43:34,812 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:43:34,812 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:43:34,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-14 21:43:34,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-14 21:43:34,910 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-14 21:43:34,915 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-14 21:43:34,920 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:43:34,925 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-14 21:43:34,927 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-14 21:43:34,927 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 21:43:34,935 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 12288
2020-06-14 21:43:34,948 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 21ms
2020-06-14 21:43:34,948 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 21ms
2020-06-14 21:43:34,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-14 21:43:34,949 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-14 21:43:34,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 1ms
2020-06-14 21:43:34,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 2ms
2020-06-14 21:43:34,966 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1803689635 ms.
2020-06-14 21:43:34,999 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/15/20, 1:09 AM with interval of 21600000ms
2020-06-14 21:43:35,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-14 21:43:35,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-14 21:43:35,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-14 21:43:35,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaf454e8f263b4419,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-14 21:43:35,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 05:04:33,500 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-810358025-127.0.0.1-1592131473415 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2020-06-15 06:04:07,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaf454e8f263b441a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-15 06:04:07,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 07:52:35,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741825_1001 src: /127.0.0.1:59757 dest: /127.0.0.1:9866
2020-06-15 07:52:35,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59757, dest: /127.0.0.1:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741825_1001, duration(ns): 13059830
2020-06-15 07:52:35,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741826_1002 src: /127.0.0.1:59758 dest: /127.0.0.1:9866
2020-06-15 07:52:36,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59758, dest: /127.0.0.1:9866, bytes: 690, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741826_1002, duration(ns): 1380491
2020-06-15 07:52:36,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741827_1003 src: /127.0.0.1:59759 dest: /127.0.0.1:9866
2020-06-15 07:52:36,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59759, dest: /127.0.0.1:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741827_1003, duration(ns): 1352849
2020-06-15 07:52:36,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741828_1004 src: /127.0.0.1:59760 dest: /127.0.0.1:9866
2020-06-15 07:52:36,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59760, dest: /127.0.0.1:9866, bytes: 967, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741828_1004, duration(ns): 1751515
2020-06-15 07:52:36,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741829_1005 src: /127.0.0.1:59761 dest: /127.0.0.1:9866
2020-06-15 07:52:36,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59761, dest: /127.0.0.1:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741829_1005, duration(ns): 1639662
2020-06-15 07:52:36,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741830_1006 src: /127.0.0.1:59762 dest: /127.0.0.1:9866
2020-06-15 07:52:36,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59762, dest: /127.0.0.1:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741830_1006, duration(ns): 1922394
2020-06-15 07:52:36,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741831_1007 src: /127.0.0.1:59763 dest: /127.0.0.1:9866
2020-06-15 07:52:36,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59763, dest: /127.0.0.1:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741831_1007, duration(ns): 2107919
2020-06-15 07:52:36,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741832_1008 src: /127.0.0.1:59764 dest: /127.0.0.1:9866
2020-06-15 07:52:36,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59764, dest: /127.0.0.1:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741832_1008, duration(ns): 1664284
2020-06-15 07:52:36,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741833_1009 src: /127.0.0.1:59765 dest: /127.0.0.1:9866
2020-06-15 07:52:36,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59765, dest: /127.0.0.1:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741833_1009, duration(ns): 1541444
2020-06-15 07:52:36,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741834_1010 src: /127.0.0.1:59766 dest: /127.0.0.1:9866
2020-06-15 07:52:36,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59766, dest: /127.0.0.1:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741834_1010, duration(ns): 1588404
2020-06-15 07:52:36,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741835_1011 src: /127.0.0.1:59767 dest: /127.0.0.1:9866
2020-06-15 07:52:36,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59767, dest: /127.0.0.1:9866, bytes: 6056, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741835_1011, duration(ns): 1875141
2020-06-15 07:52:36,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741836_1012 src: /127.0.0.1:59768 dest: /127.0.0.1:9866
2020-06-15 07:52:36,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59768, dest: /127.0.0.1:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741836_1012, duration(ns): 1839437
2020-06-15 07:52:36,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741837_1013 src: /127.0.0.1:59769 dest: /127.0.0.1:9866
2020-06-15 07:52:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59769, dest: /127.0.0.1:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741837_1013, duration(ns): 1801554
2020-06-15 07:52:36,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741838_1014 src: /127.0.0.1:59770 dest: /127.0.0.1:9866
2020-06-15 07:52:36,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59770, dest: /127.0.0.1:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741838_1014, duration(ns): 2313541
2020-06-15 07:52:36,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741839_1015 src: /127.0.0.1:59771 dest: /127.0.0.1:9866
2020-06-15 07:52:36,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59771, dest: /127.0.0.1:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741839_1015, duration(ns): 1416649
2020-06-15 07:52:36,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741840_1016 src: /127.0.0.1:59772 dest: /127.0.0.1:9866
2020-06-15 07:52:36,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59772, dest: /127.0.0.1:9866, bytes: 1070, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741840_1016, duration(ns): 1588741
2020-06-15 07:52:36,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741841_1017 src: /127.0.0.1:59773 dest: /127.0.0.1:9866
2020-06-15 07:52:36,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59773, dest: /127.0.0.1:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741841_1017, duration(ns): 1364035
2020-06-15 07:52:36,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741842_1018 src: /127.0.0.1:59774 dest: /127.0.0.1:9866
2020-06-15 07:52:36,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59774, dest: /127.0.0.1:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741842_1018, duration(ns): 1644247
2020-06-15 07:52:36,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:36,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741843_1019 src: /127.0.0.1:59775 dest: /127.0.0.1:9866
2020-06-15 07:52:36,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59775, dest: /127.0.0.1:9866, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741843_1019, duration(ns): 1994553
2020-06-15 07:52:36,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741844_1020 src: /127.0.0.1:59776 dest: /127.0.0.1:9866
2020-06-15 07:52:37,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59776, dest: /127.0.0.1:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741844_1020, duration(ns): 2289397
2020-06-15 07:52:37,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741845_1021 src: /127.0.0.1:59777 dest: /127.0.0.1:9866
2020-06-15 07:52:37,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59777, dest: /127.0.0.1:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741845_1021, duration(ns): 1715233
2020-06-15 07:52:37,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741846_1022 src: /127.0.0.1:59778 dest: /127.0.0.1:9866
2020-06-15 07:52:37,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59778, dest: /127.0.0.1:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741846_1022, duration(ns): 1528242
2020-06-15 07:52:37,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741847_1023 src: /127.0.0.1:59779 dest: /127.0.0.1:9866
2020-06-15 07:52:37,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59779, dest: /127.0.0.1:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741847_1023, duration(ns): 1295562
2020-06-15 07:52:37,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741848_1024 src: /127.0.0.1:59780 dest: /127.0.0.1:9866
2020-06-15 07:52:37,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59780, dest: /127.0.0.1:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741848_1024, duration(ns): 1045131
2020-06-15 07:52:37,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741849_1025 src: /127.0.0.1:59781 dest: /127.0.0.1:9866
2020-06-15 07:52:37,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59781, dest: /127.0.0.1:9866, bytes: 8260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741849_1025, duration(ns): 996655
2020-06-15 07:52:37,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741850_1026 src: /127.0.0.1:59782 dest: /127.0.0.1:9866
2020-06-15 07:52:37,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59782, dest: /127.0.0.1:9866, bytes: 1161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741850_1026, duration(ns): 1399122
2020-06-15 07:52:37,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741851_1027 src: /127.0.0.1:59783 dest: /127.0.0.1:9866
2020-06-15 07:52:37,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59783, dest: /127.0.0.1:9866, bytes: 16755, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741851_1027, duration(ns): 1049839
2020-06-15 07:52:37,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741852_1028 src: /127.0.0.1:59784 dest: /127.0.0.1:9866
2020-06-15 07:52:37,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59784, dest: /127.0.0.1:9866, bytes: 13326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741852_1028, duration(ns): 1262084
2020-06-15 07:52:37,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2020-06-15 07:52:37,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741853_1029 src: /127.0.0.1:59785 dest: /127.0.0.1:9866
2020-06-15 07:52:37,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59785, dest: /127.0.0.1:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1450042827_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741853_1029, duration(ns): 9054551
2020-06-15 07:52:37,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2020-06-15 08:20:50,388 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: DestHost:destPort localhost:9000 , LocalHost:localPort jingyangs-iMac.local/127.0.0.1:0. Failed on local exception: java.io.IOException: Connection reset by peer
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:808)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy18.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.io.IOException: Connection reset by peer
	at java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:382)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:393)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-06-15 08:20:50,653 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-15 08:20:50,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at jingyangs-iMac.local/127.0.0.1
************************************************************/
2020-06-15 08:22:15,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = jingyangs-iMac.local/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-15 08:22:15,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-15 08:22:15,360 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-15 08:22:15,536 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:22:15,623 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-15 08:22:15,720 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-15 08:22:15,720 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-15 08:22:15,876 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-15 08:22:15,878 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-15 08:22:15,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-15 08:22:15,885 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-15 08:22:15,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-15 08:22:15,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0:0:0:0:0:0:0:0:9866
2020-06-15 08:22:15,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-15 08:22:15,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-15 08:22:15,935 INFO org.eclipse.jetty.util.log: Logging initialized @1355ms
2020-06-15 08:22:16,002 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-15 08:22:16,004 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-15 08:22:16,010 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-15 08:22:16,011 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-15 08:22:16,012 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-15 08:22:16,012 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-15 08:22:16,026 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 60571
2020-06-15 08:22:16,027 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-15 08:22:16,046 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-15 08:22:16,047 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38d5b107{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-15 08:22:16,109 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3d7cc3cb{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-15 08:22:16,114 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@759d81f3{HTTP/1.1,[http/1.1]}{localhost:60571}
2020-06-15 08:22:16,114 INFO org.eclipse.jetty.server.Server: Started @1534ms
2020-06-15 08:22:16,267 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0:0:0:0:0:0:0:0:9864
2020-06-15 08:22:16,273 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-15 08:22:16,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-15 08:22:16,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-15 08:22:16,305 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-15 08:22:16,316 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-15 08:22:16,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0:0:0:0:0:0:0:0:9867
2020-06-15 08:22:16,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-15 08:22:16,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-15 08:22:16,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-15 08:22:16,487 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-15 08:22:16,488 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-15 08:22:16,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-15 08:22:16,691 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-15 08:22:16,699 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 64880@jingyangs-iMac.local
2020-06-15 08:22:16,734 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:22:16,734 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:22:16,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-15 08:22:16,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-15 08:22:16,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-15 08:22:16,853 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-15 08:22:16,859 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:22:16,882 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:22:16,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:22:16,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-15 08:22:16,891 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 303104
2020-06-15 08:22:16,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 22ms
2020-06-15 08:22:16,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 22ms
2020-06-15 08:22:16,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-15 08:22:16,909 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-15 08:22:16,926 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 17ms
2020-06-15 08:22:16,927 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 20ms
2020-06-15 08:22:16,969 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1765367632 ms.
2020-06-15 08:22:17,014 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/15/20, 9:51 AM with interval of 21600000ms
2020-06-15 08:22:17,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-15 08:22:17,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-15 08:22:17,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-15 08:22:17,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x68026ede74817fa0,  containing 1 storage report(s), of which we sent 1. The reports had 29 total blocks and used 1 RPC(s). This took 3 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-15 08:22:17,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:23:25,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741854_1030 src: /127.0.0.1:60626 dest: /127.0.0.1:9866
2020-06-15 08:23:25,825 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60626, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_751227835_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741854_1030, duration(ns): 14461698
2020-06-15 08:23:25,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2020-06-15 08:23:26,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741855_1031 src: /127.0.0.1:60627 dest: /127.0.0.1:9866
2020-06-15 08:23:26,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60627, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_751227835_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741855_1031, duration(ns): 2289768
2020-06-15 08:23:26,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2020-06-15 08:23:26,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741856_1032 src: /127.0.0.1:60628 dest: /127.0.0.1:9866
2020-06-15 08:23:26,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60628, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_751227835_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741856_1032, duration(ns): 2157600
2020-06-15 08:23:26,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2020-06-15 08:23:27,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741857_1033 src: /127.0.0.1:60629 dest: /127.0.0.1:9866
2020-06-15 08:23:27,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60629, dest: /127.0.0.1:9866, bytes: 193009, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_751227835_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741857_1033, duration(ns): 2629651
2020-06-15 08:23:27,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2020-06-15 08:23:32,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741858_1034 src: /127.0.0.1:60635 dest: /127.0.0.1:9866
2020-06-15 08:23:32,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60635, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_751227835_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741858_1034, duration(ns): 3910698
2020-06-15 08:23:32,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2020-06-15 08:23:35,162 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2020-06-15 08:23:35,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741858_1034 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741858
2020-06-15 08:43:43,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741859_1035 src: /127.0.0.1:60903 dest: /127.0.0.1:9866
2020-06-15 08:43:43,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60903, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-493611602_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741859_1035, duration(ns): 11890257
2020-06-15 08:43:43,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2020-06-15 08:43:43,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741860_1036 src: /127.0.0.1:60904 dest: /127.0.0.1:9866
2020-06-15 08:43:43,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60904, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-493611602_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741860_1036, duration(ns): 2244413
2020-06-15 08:43:43,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2020-06-15 08:43:43,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741861_1037 src: /127.0.0.1:60905 dest: /127.0.0.1:9866
2020-06-15 08:43:43,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60905, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-493611602_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741861_1037, duration(ns): 3161989
2020-06-15 08:43:43,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2020-06-15 08:43:44,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741862_1038 src: /127.0.0.1:60906 dest: /127.0.0.1:9866
2020-06-15 08:43:44,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60906, dest: /127.0.0.1:9866, bytes: 193492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-493611602_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741862_1038, duration(ns): 10548162
2020-06-15 08:43:44,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2020-06-15 08:43:47,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741863_1039 src: /127.0.0.1:60912 dest: /127.0.0.1:9866
2020-06-15 08:43:47,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60912, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-493611602_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741863_1039, duration(ns): 3892661
2020-06-15 08:43:47,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2020-06-15 08:43:51,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 replica FinalizedReplica, blk_1073741863_1039, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2020-06-15 08:43:51,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741863_1039 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741863
2020-06-15 08:44:42,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741864_1040 src: /127.0.0.1:60924 dest: /127.0.0.1:9866
2020-06-15 08:44:42,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60924, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1941446646_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741864_1040, duration(ns): 13317544
2020-06-15 08:44:42,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:43,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741865_1041 src: /127.0.0.1:60925 dest: /127.0.0.1:9866
2020-06-15 08:44:43,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60925, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1941446646_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741865_1041, duration(ns): 2017448
2020-06-15 08:44:43,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:43,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741866_1042 src: /127.0.0.1:60926 dest: /127.0.0.1:9866
2020-06-15 08:44:43,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60926, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1941446646_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741866_1042, duration(ns): 1826998
2020-06-15 08:44:43,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:43,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741867_1043 src: /127.0.0.1:60927 dest: /127.0.0.1:9866
2020-06-15 08:44:43,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60927, dest: /127.0.0.1:9866, bytes: 193476, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1941446646_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741867_1043, duration(ns): 5163877
2020-06-15 08:44:43,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:46,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741868_1044 src: /127.0.0.1:60935 dest: /127.0.0.1:9866
2020-06-15 08:44:46,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60935, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1941446646_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741868_1044, duration(ns): 3329311
2020-06-15 08:44:46,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:51,218 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 replica FinalizedReplica, blk_1073741868_1044, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2020-06-15 08:44:51,219 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741868_1044 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741868
2020-06-15 08:44:58,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741869_1045 src: /127.0.0.1:60942 dest: /127.0.0.1:9866
2020-06-15 08:44:58,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60942, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859138093_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741869_1045, duration(ns): 10736344
2020-06-15 08:44:58,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:58,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741870_1046 src: /127.0.0.1:60943 dest: /127.0.0.1:9866
2020-06-15 08:44:58,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60943, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859138093_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741870_1046, duration(ns): 2177381
2020-06-15 08:44:58,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:58,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741871_1047 src: /127.0.0.1:60944 dest: /127.0.0.1:9866
2020-06-15 08:44:58,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60944, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859138093_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741871_1047, duration(ns): 1879769
2020-06-15 08:44:58,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2020-06-15 08:44:58,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741872_1048 src: /127.0.0.1:60947 dest: /127.0.0.1:9866
2020-06-15 08:44:58,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60947, dest: /127.0.0.1:9866, bytes: 193476, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859138093_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741872_1048, duration(ns): 4418713
2020-06-15 08:44:58,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2020-06-15 08:45:01,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741873_1049 src: /127.0.0.1:60953 dest: /127.0.0.1:9866
2020-06-15 08:45:01,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60953, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1859138093_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741873_1049, duration(ns): 4639505
2020-06-15 08:45:01,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2020-06-15 08:45:06,229 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741873_1049 replica FinalizedReplica, blk_1073741873_1049, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741873 for deletion
2020-06-15 08:45:06,229 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741873_1049 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741873
2020-06-15 08:46:59,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741874_1050 src: /127.0.0.1:60969 dest: /127.0.0.1:9866
2020-06-15 08:46:59,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60969, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1057375809_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741874_1050, duration(ns): 12141592
2020-06-15 08:46:59,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2020-06-15 08:46:59,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741875_1051 src: /127.0.0.1:60970 dest: /127.0.0.1:9866
2020-06-15 08:46:59,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60970, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1057375809_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741875_1051, duration(ns): 2673540
2020-06-15 08:46:59,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2020-06-15 08:46:59,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741876_1052 src: /127.0.0.1:60971 dest: /127.0.0.1:9866
2020-06-15 08:46:59,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60971, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1057375809_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741876_1052, duration(ns): 1495022
2020-06-15 08:46:59,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2020-06-15 08:46:59,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741877_1053 src: /127.0.0.1:60972 dest: /127.0.0.1:9866
2020-06-15 08:46:59,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60972, dest: /127.0.0.1:9866, bytes: 193492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1057375809_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741877_1053, duration(ns): 10982554
2020-06-15 08:46:59,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2020-06-15 08:47:02,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741878_1054 src: /127.0.0.1:60978 dest: /127.0.0.1:9866
2020-06-15 08:47:02,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60978, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1057375809_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741878_1054, duration(ns): 2346901
2020-06-15 08:47:02,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2020-06-15 08:47:06,332 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 replica FinalizedReplica, blk_1073741878_1054, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2020-06-15 08:47:06,332 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741878_1054 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741878
2020-06-15 08:47:45,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "jingyangs-iMac.local/127.0.0.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:488)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy18.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.base/java.lang.Thread.run(Thread.java:844)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-06-15 08:47:45,710 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-06-15 08:47:45,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at jingyangs-iMac.local/127.0.0.1
************************************************************/
2020-06-15 08:48:09,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = jingyangs-iMac.local/127.0.0.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /usr/local/Cellar/hadoop/3.2.1_1/libexec/etc/hadoop:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/guice-4.0.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 9.0.1
************************************************************/
2020-06-15 08:48:09,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-06-15 08:48:09,906 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-06-15 08:48:10,090 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:48:10,167 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-06-15 08:48:10,260 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-06-15 08:48:10,260 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-06-15 08:48:10,415 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-15 08:48:10,417 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-06-15 08:48:10,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is localhost
2020-06-15 08:48:10,421 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-06-15 08:48:10,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-06-15 08:48:10,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0:0:0:0:0:0:0:0:9866
2020-06-15 08:48:10,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-06-15 08:48:10,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-06-15 08:48:10,474 INFO org.eclipse.jetty.util.log: Logging initialized @1288ms
2020-06-15 08:48:10,545 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-06-15 08:48:10,548 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-06-15 08:48:10,553 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-06-15 08:48:10,555 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-06-15 08:48:10,555 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-06-15 08:48:10,555 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-06-15 08:48:10,571 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 60989
2020-06-15 08:48:10,572 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-06-15 08:48:10,592 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@27f0ad19{/logs,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/logs/,AVAILABLE}
2020-06-15 08:48:10,593 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@38d5b107{/static,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-06-15 08:48:10,655 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3d7cc3cb{/,file:///usr/local/Cellar/hadoop/3.2.1_1/libexec/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-06-15 08:48:10,660 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@759d81f3{HTTP/1.1,[http/1.1]}{localhost:60989}
2020-06-15 08:48:10,660 INFO org.eclipse.jetty.server.Server: Started @1475ms
2020-06-15 08:48:10,799 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0:0:0:0:0:0:0:0:9864
2020-06-15 08:48:10,805 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-06-15 08:48:10,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jing
2020-06-15 08:48:10,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-06-15 08:48:10,846 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-06-15 08:48:10,856 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-06-15 08:48:10,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0:0:0:0:0:0:0:0:9867
2020-06-15 08:48:11,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-06-15 08:48:11,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-06-15 08:48:11,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-06-15 08:48:11,021 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-06-15 08:48:11,021 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-06-15 08:48:11,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-06-15 08:48:11,219 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-06-15 08:48:11,230 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/in_use.lock acquired by nodename 67596@jingyangs-iMac.local
2020-06-15 08:48:11,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:48:11,259 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:48:11,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1881303659;bpid=BP-810358025-127.0.0.1-1592131473415;lv=-57;nsInfo=lv=-65;cid=CID-0d6d6cae-408e-4126-9de9-ed6b6c3a1863;nsid=1881303659;c=1592131473415;bpid=BP-810358025-127.0.0.1-1592131473415;dnuuid=51ec38b1-6bff-4753-abfc-a5a7f97c7aca
2020-06-15 08:48:11,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-a0afa056-2184-42bb-9b38-9b26368747d7
2020-06-15 08:48:11,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, StorageType: DISK
2020-06-15 08:48:11,367 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-06-15 08:48:11,374 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:48:11,389 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
2020-06-15 08:48:11,390 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:48:11,391 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-15 08:48:11,399 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current: 2916856
2020-06-15 08:48:11,413 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-810358025-127.0.0.1-1592131473415 on /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 23ms
2020-06-15 08:48:11,413 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-810358025-127.0.0.1-1592131473415: 23ms
2020-06-15 08:48:11,417 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data...
2020-06-15 08:48:11,417 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/replicas doesn't exist 
2020-06-15 08:48:11,433 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-810358025-127.0.0.1-1592131473415 on volume /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data: 15ms
2020-06-15 08:48:11,433 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-810358025-127.0.0.1-1592131473415: 17ms
2020-06-15 08:48:11,454 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data, DS-a0afa056-2184-42bb-9b38-9b26368747d7): no suitable block pools found to scan.  Waiting 1763813147 ms.
2020-06-15 08:48:11,475 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 6/15/20, 12:50 PM with interval of 21600000ms
2020-06-15 08:48:11,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-06-15 08:48:11,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-810358025-127.0.0.1-1592131473415 (Datanode Uuid 51ec38b1-6bff-4753-abfc-a5a7f97c7aca) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-06-15 08:48:11,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-06-15 08:48:11,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xca837a77b8b24c9c,  containing 1 storage report(s), of which we sent 1. The reports had 49 total blocks and used 1 RPC(s). This took 4 msec to generate and 53 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-06-15 08:48:11,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-810358025-127.0.0.1-1592131473415
2020-06-15 08:49:18,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741879_1055 src: /127.0.0.1:61009 dest: /127.0.0.1:9866
2020-06-15 08:49:18,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61009, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-987798889_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741879_1055, duration(ns): 15220276
2020-06-15 08:49:18,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2020-06-15 08:49:19,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741880_1056 src: /127.0.0.1:61010 dest: /127.0.0.1:9866
2020-06-15 08:49:19,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61010, dest: /127.0.0.1:9866, bytes: 3716, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-987798889_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741880_1056, duration(ns): 2457544
2020-06-15 08:49:19,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2020-06-15 08:49:19,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741881_1057 src: /127.0.0.1:61011 dest: /127.0.0.1:9866
2020-06-15 08:49:19,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61011, dest: /127.0.0.1:9866, bytes: 484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-987798889_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741881_1057, duration(ns): 3891971
2020-06-15 08:49:19,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2020-06-15 08:49:19,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741882_1058 src: /127.0.0.1:61012 dest: /127.0.0.1:9866
2020-06-15 08:49:19,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61012, dest: /127.0.0.1:9866, bytes: 193492, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-987798889_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741882_1058, duration(ns): 2571137
2020-06-15 08:49:19,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2020-06-15 08:49:24,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-810358025-127.0.0.1-1592131473415:blk_1073741883_1059 src: /127.0.0.1:61018 dest: /127.0.0.1:9866
2020-06-15 08:49:24,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:61018, dest: /127.0.0.1:9866, bytes: 316534, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-987798889_1, offset: 0, srvID: 51ec38b1-6bff-4753-abfc-a5a7f97c7aca, blockid: BP-810358025-127.0.0.1-1592131473415:blk_1073741883_1059, duration(ns): 5259359
2020-06-15 08:49:24,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-810358025-127.0.0.1-1592131473415:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2020-06-15 08:49:29,593 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741883_1059 replica FinalizedReplica, blk_1073741883_1059, FINALIZED
  getNumBytes()     = 316534
  getBytesOnDisk()  = 316534
  getVisibleLength()= 316534
  getVolume()       = /usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data
  getBlockURI()     = file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741883 for deletion
2020-06-15 08:49:29,595 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-810358025-127.0.0.1-1592131473415 blk_1073741883_1059 URI file:/usr/local/Cellar/hadoop/3.2.1_1/tmp/dfs/data/current/BP-810358025-127.0.0.1-1592131473415/current/finalized/subdir0/subdir0/blk_1073741883
